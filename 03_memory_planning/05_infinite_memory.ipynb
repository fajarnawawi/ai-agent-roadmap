{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’­ Project 5: The Infinite Companion\n",
    "\n",
    "**Objective:** Build a chatbot that remembers facts about you across sessions.\n",
    "\n",
    "## ðŸ“– The Memory Problem\n",
    "\n",
    "LLMs have a context window limit (e.g., 8K, 32K tokens). For long conversations:\n",
    "- You can't fit entire history\n",
    "- Information gets lost\n",
    "- No persistence across sessions\n",
    "\n",
    "## ðŸŽ¯ Solution: Memory Systems\n",
    "\n",
    "1. **SummaryMemory**: Compress old messages into summaries\n",
    "2. **EntityMemory**: Extract and store key facts\n",
    "3. **Sliding Window**: Keep only recent messages\n",
    "4. **Semantic Retrieval**: Fetch relevant past context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryMemory:\n",
    "    \"\"\"\n",
    "    Maintains conversation summary when messages exceed limit.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_messages: int = 10):\n",
    "        self.max_messages = max_messages\n",
    "        self.summary = \"\"\n",
    "        self.recent_messages = []\n",
    "    \n",
    "    def add_message(self, role: str, content: str):\n",
    "        \"\"\"Add a message and summarize if needed.\"\"\"\n",
    "        self.recent_messages.append({\"role\": role, \"content\": content})\n",
    "        \n",
    "        if len(self.recent_messages) > self.max_messages:\n",
    "            self._summarize_and_compress()\n",
    "    \n",
    "    def _summarize_and_compress(self):\n",
    "        \"\"\"Summarize older messages and keep only recent ones.\"\"\"\n",
    "        # Take first half for summarization\n",
    "        to_summarize = self.recent_messages[:self.max_messages // 2]\n",
    "        \n",
    "        # Create summary prompt\n",
    "        messages_text = \"\\n\".join([\n",
    "            f\"{msg['role']}: {msg['content']}\" for msg in to_summarize\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"Summarize this conversation, preserving key facts and context:\n",
    "\n",
    "{messages_text}\n",
    "\n",
    "Previous summary: {self.summary if self.summary else 'None'}\n",
    "\n",
    "Provide a concise summary:\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        self.summary = response.choices[0].message.content\n",
    "        self.recent_messages = self.recent_messages[self.max_messages // 2:]\n",
    "        \n",
    "        print(f\"ðŸ“ Summarized {len(to_summarize)} messages\")\n",
    "    \n",
    "    def get_context(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Get formatted context for LLM.\"\"\"\n",
    "        context = []\n",
    "        \n",
    "        if self.summary:\n",
    "            context.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Conversation summary: {self.summary}\"\n",
    "            })\n",
    "        \n",
    "        context.extend(self.recent_messages)\n",
    "        return context\n",
    "\n",
    "# Test\n",
    "memory = SummaryMemory(max_messages=4)\n",
    "print(\"âœ… SummaryMemory initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement Entity Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityMemory:\n",
    "    \"\"\"\n",
    "    Extracts and stores facts about entities (users, topics, etc.).\n",
    "    \"\"\"\n",
    "    def __init__(self, db_path: str = \"entity_memory.db\"):\n",
    "        self.db_path = db_path\n",
    "        self._init_db()\n",
    "    \n",
    "    def _init_db(self):\n",
    "        \"\"\"Initialize SQLite database.\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS entities (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                entity_type TEXT,\n",
    "                entity_name TEXT,\n",
    "                fact TEXT,\n",
    "                timestamp TEXT\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def extract_and_store(self, message: str):\n",
    "        \"\"\"Extract entities and facts from message.\"\"\"\n",
    "        prompt = f\"\"\"Extract key facts from this message. Format as JSON list:\n",
    "[{{\"type\": \"person/preference/fact\", \"entity\": \"name\", \"fact\": \"description\"}}]\n",
    "\n",
    "Message: {message}\n",
    "\n",
    "Only extract significant, memorable facts. Return empty list if none.\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            entities = json.loads(response.choices[0].message.content)\n",
    "            self._store_entities(entities)\n",
    "            return len(entities)\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def _store_entities(self, entities: List[Dict]):\n",
    "        \"\"\"Store entities in database.\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        for entity in entities:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO entities (entity_type, entity_name, fact, timestamp)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "            ''', (\n",
    "                entity.get('type', 'unknown'),\n",
    "                entity.get('entity', 'unknown'),\n",
    "                entity.get('fact', ''),\n",
    "                datetime.now().isoformat()\n",
    "            ))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def get_all_facts(self) -> str:\n",
    "        \"\"\"Get all stored facts as text.\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT entity_type, entity_name, fact FROM entities')\n",
    "        results = cursor.fetchall()\n",
    "        conn.close()\n",
    "        \n",
    "        if not results:\n",
    "            return \"No facts stored yet.\"\n",
    "        \n",
    "        facts = [f\"- {entity_name} ({entity_type}): {fact}\" \n",
    "                for entity_type, entity_name, fact in results]\n",
    "        return \"\\n\".join(facts)\n",
    "\n",
    "# Test\n",
    "entity_memory = EntityMemory()\n",
    "print(\"âœ… EntityMemory initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Build Chatbot with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryChatbot:\n",
    "    \"\"\"\n",
    "    Chatbot with both summary and entity memory.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.summary_memory = SummaryMemory(max_messages=8)\n",
    "        self.entity_memory = EntityMemory()\n",
    "        self.system_prompt = \"\"\"You are a friendly AI assistant with perfect memory.\n",
    "You remember facts about the user and use them in conversation naturally.\n",
    "Be warm, engaging, and show that you remember previous conversations.\"\"\"\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Process a message and return response.\"\"\"\n",
    "        # Extract and store entities from user message\n",
    "        facts_extracted = self.entity_memory.extract_and_store(user_message)\n",
    "        if facts_extracted > 0:\n",
    "            print(f\"ðŸ’¾ Stored {facts_extracted} new facts\")\n",
    "        \n",
    "        # Add to conversation memory\n",
    "        self.summary_memory.add_message(\"user\", user_message)\n",
    "        \n",
    "        # Build context with stored facts\n",
    "        all_facts = self.entity_memory.get_all_facts()\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"system\", \"content\": f\"Facts you know:\\n{all_facts}\"},\n",
    "        ]\n",
    "        messages.extend(self.summary_memory.get_context())\n",
    "        \n",
    "        # Get response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message.content\n",
    "        self.summary_memory.add_message(\"assistant\", assistant_message)\n",
    "        \n",
    "        return assistant_message\n",
    "\n",
    "# Initialize chatbot\n",
    "bot = MemoryChatbot()\n",
    "print(\"ðŸ¤– Memory Chatbot ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation 1: Share information\n",
    "print(\"User: Hi! My name is Alex and I love Python programming.\")\n",
    "response = bot.chat(\"Hi! My name is Alex and I love Python programming.\")\n",
    "print(f\"Bot: {response}\\n\")\n",
    "\n",
    "print(\"User: I'm working on an AI agent project right now.\")\n",
    "response = bot.chat(\"I'm working on an AI agent project right now.\")\n",
    "print(f\"Bot: {response}\\n\")\n",
    "\n",
    "print(\"User: My favorite food is pizza.\")\n",
    "response = bot.chat(\"My favorite food is pizza.\")\n",
    "print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation 2: Test memory recall (simulate new session)\n",
    "bot2 = MemoryChatbot()  # New instance, but same database\n",
    "\n",
    "print(\"User: What do you know about me?\")\n",
    "response = bot2.chat(\"What do you know about me?\")\n",
    "print(f\"Bot: {response}\\n\")\n",
    "\n",
    "print(\"User: What food do I like?\")\n",
    "response = bot2.chat(\"What food do I like?\")\n",
    "print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Key Takeaways\n",
    "\n",
    "### Memory Strategies:\n",
    "\n",
    "1. **Summary Memory**: Compress history to fit context\n",
    "2. **Entity Memory**: Extract and persist key facts\n",
    "3. **Sliding Window**: Keep recent, summarize old\n",
    "4. **Semantic Search**: Retrieve relevant past context (Phase 2!)\n",
    "\n",
    "### Production Tips:\n",
    "\n",
    "- Use vector DBs for semantic memory search\n",
    "- Implement memory decay (older facts less relevant)\n",
    "- Add user privacy controls\n",
    "- Optimize summarization frequency\n",
    "\n",
    "### Next: Planning!\n",
    "\n",
    "Module 6 adds hierarchical planning for complex multi-step tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
