{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Project 3: The Hard-Coded Agent\n",
    "\n",
    "**Objective:** Build an AI Agent loop from scratch **without frameworks**.\n",
    "\n",
    "## ðŸ“– What You'll Learn\n",
    "\n",
    "- The ReAct pattern (Reasoning + Acting)\n",
    "- How to parse LLM outputs into structured actions\n",
    "- Building agent loops with Python\n",
    "- Tool execution and observation feedback\n",
    "\n",
    "## ðŸŽ¯ The ReAct Pattern\n",
    "\n",
    "```\n",
    "Loop:\n",
    "  1. THOUGHT: Reason about what to do\n",
    "  2. ACTION: Call a tool/function\n",
    "  3. OBSERVATION: Get the result\n",
    "  4. Repeat until task is complete\n",
    "```\n",
    "\n",
    "This is the foundation of **every AI agent framework** (LangChain, AutoGPT, etc.)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, Any, Optional\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Define Tools (Functions)\n",
    "\n",
    "Our agent will have access to two simple tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simulated weather API.\n",
    "    In production, this would call a real weather service.\n",
    "    \"\"\"\n",
    "    # Mock data\n",
    "    weather_data = {\n",
    "        \"london\": {\"temperature\": \"15Â°C\", \"condition\": \"Cloudy\", \"humidity\": \"75%\"},\n",
    "        \"new york\": {\"temperature\": \"22Â°C\", \"condition\": \"Sunny\", \"humidity\": \"60%\"},\n",
    "        \"tokyo\": {\"temperature\": \"18Â°C\", \"condition\": \"Rainy\", \"humidity\": \"85%\"},\n",
    "        \"paris\": {\"temperature\": \"17Â°C\", \"condition\": \"Partly Cloudy\", \"humidity\": \"70%\"},\n",
    "    }\n",
    "    \n",
    "    city_lower = city.lower()\n",
    "    if city_lower in weather_data:\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"city\": city,\n",
    "            \"data\": weather_data[city_lower]\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Weather data not available for {city}\"\n",
    "        }\n",
    "\n",
    "def calculator(expression: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Safe calculator that evaluates mathematical expressions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Only allow basic math operations for security\n",
    "        allowed_chars = set('0123456789+-*/(). ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Invalid characters in expression\"\n",
    "            }\n",
    "        \n",
    "        result = eval(expression)\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"expression\": expression,\n",
    "            \"result\": result\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Test the tools\n",
    "print(\"ðŸ§ª Testing tools:\\n\")\n",
    "print(\"Weather in London:\", get_weather(\"London\"))\n",
    "print(\"Calculate 25 * 4:\", calculator(\"25 * 4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Design the System Prompt\n",
    "\n",
    "The prompt is **critical**. It teaches the LLM:\n",
    "1. What tools it has access to\n",
    "2. The exact format to use\n",
    "3. When to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an AI agent with access to tools. Your job is to answer questions by using these tools.\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "1. get_weather(city: str) - Get current weather for a city\n",
    "   Example: get_weather(\"London\")\n",
    "\n",
    "2. calculator(expression: str) - Calculate mathematical expressions\n",
    "   Example: calculator(\"25 * 4\")\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "You must ALWAYS respond in this exact format:\n",
    "\n",
    "THOUGHT: [Your reasoning about what to do next]\n",
    "ACTION: [tool_name(arguments)] OR None if ready to answer\n",
    "OBSERVATION: [Wait for the system to provide this]\n",
    "ANSWER: [Only provide this when you have enough information]\n",
    "\n",
    "RULES:\n",
    "1. Always start with THOUGHT\n",
    "2. If you need information, specify an ACTION\n",
    "3. If you have enough information, set ACTION to None and provide ANSWER\n",
    "4. Never make up tool results - wait for OBSERVATION\n",
    "5. Keep thoughts concise and focused\n",
    "\n",
    "EXAMPLE:\n",
    "Question: What's the weather in Paris?\n",
    "THOUGHT: I need to check the weather for Paris\n",
    "ACTION: get_weather(\"Paris\")\n",
    "OBSERVATION: {\"success\": true, \"data\": {\"temperature\": \"17Â°C\", \"condition\": \"Partly Cloudy\"}}\n",
    "THOUGHT: I have the weather information\n",
    "ACTION: None\n",
    "ANSWER: The weather in Paris is 17Â°C and partly cloudy.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ðŸ“‹ System Prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(SYSTEM_PROMPT)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Parse LLM Output\n",
    "\n",
    "Extract structured actions from the LLM's text response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_action(text: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse the ACTION line from LLM response.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with 'tool' and 'args', or None if ACTION is None\n",
    "    \"\"\"\n",
    "    # Find the ACTION line\n",
    "    action_match = re.search(r'ACTION:\\s*(.+)', text)\n",
    "    if not action_match:\n",
    "        return None\n",
    "    \n",
    "    action_text = action_match.group(1).strip()\n",
    "    \n",
    "    # Check if action is None (agent is ready to answer)\n",
    "    if action_text.lower() == 'none':\n",
    "        return None\n",
    "    \n",
    "    # Parse tool call: tool_name(arguments)\n",
    "    tool_match = re.match(r'(\\w+)\\((.*)\\)', action_text)\n",
    "    if not tool_match:\n",
    "        raise ValueError(f\"Invalid action format: {action_text}\")\n",
    "    \n",
    "    tool_name = tool_match.group(1)\n",
    "    args = tool_match.group(2).strip('\"\\' ')  # Remove quotes\n",
    "    \n",
    "    return {\n",
    "        'tool': tool_name,\n",
    "        'args': args\n",
    "    }\n",
    "\n",
    "# Test the parser\n",
    "test_cases = [\n",
    "    'ACTION: get_weather(\"London\")',\n",
    "    'ACTION: calculator(\"25 * 4\")',\n",
    "    'ACTION: None',\n",
    "]\n",
    "\n",
    "print(\"ðŸ§ª Testing action parser:\\n\")\n",
    "for test in test_cases:\n",
    "    result = parse_action(test)\n",
    "    print(f\"Input:  {test}\")\n",
    "    print(f\"Output: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Execute Tools\n",
    "\n",
    "Map tool names to actual Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool registry\n",
    "TOOLS = {\n",
    "    'get_weather': get_weather,\n",
    "    'calculator': calculator,\n",
    "}\n",
    "\n",
    "def execute_action(action: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Execute a tool and return the result as a string.\n",
    "    \"\"\"\n",
    "    tool_name = action['tool']\n",
    "    args = action['args']\n",
    "    \n",
    "    if tool_name not in TOOLS:\n",
    "        return json.dumps({\"success\": False, \"error\": f\"Unknown tool: {tool_name}\"})\n",
    "    \n",
    "    # Execute the tool\n",
    "    tool_func = TOOLS[tool_name]\n",
    "    result = tool_func(args)\n",
    "    \n",
    "    return json.dumps(result)\n",
    "\n",
    "# Test execution\n",
    "test_action = {'tool': 'get_weather', 'args': 'Tokyo'}\n",
    "print(\"ðŸ§ª Testing tool execution:\")\n",
    "print(f\"Action: {test_action}\")\n",
    "print(f\"Result: {execute_action(test_action)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Build the Agent Loop\n",
    "\n",
    "Now we connect everything: LLM â†’ Parse â†’ Execute â†’ Feedback â†’ Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(question: str, max_iterations: int = 5, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Run the agent loop to answer a question.\n",
    "    \n",
    "    Args:\n",
    "        question: User's question\n",
    "        max_iterations: Maximum number of tool calls to prevent infinite loops\n",
    "        verbose: Print step-by-step execution\n",
    "    \n",
    "    Returns:\n",
    "        Final answer from the agent\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ðŸŽ¯ Question: {question}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        if verbose:\n",
    "            print(f\"ðŸ”„ Iteration {iteration + 1}\")\n",
    "            print(\"-\"*80)\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0,  # Deterministic for consistent format\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message.content\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nðŸ¤– Agent Response:\\n{assistant_message}\\n\")\n",
    "        \n",
    "        # Add to conversation history\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        # Parse action\n",
    "        try:\n",
    "            action = parse_action(assistant_message)\n",
    "        except ValueError as e:\n",
    "            if verbose:\n",
    "                print(f\"âŒ Parse error: {e}\")\n",
    "            return f\"Error: {e}\"\n",
    "        \n",
    "        # Check if agent is done\n",
    "        if action is None:\n",
    "            # Extract final answer\n",
    "            answer_match = re.search(r'ANSWER:\\s*(.+)', assistant_message, re.DOTALL)\n",
    "            if answer_match:\n",
    "                final_answer = answer_match.group(1).strip()\n",
    "                if verbose:\n",
    "                    print(\"=\"*80)\n",
    "                    print(\"âœ… Agent Complete!\")\n",
    "                    print(\"=\"*80)\n",
    "                return final_answer\n",
    "            else:\n",
    "                return \"Error: Agent finished but provided no answer\"\n",
    "        \n",
    "        # Execute tool\n",
    "        if verbose:\n",
    "            print(f\"âš™ï¸  Executing: {action['tool']}({action['args']})\")\n",
    "        \n",
    "        observation = execute_action(action)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ðŸ‘ï¸  Observation: {observation}\\n\")\n",
    "        \n",
    "        # Add observation to messages\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"OBSERVATION: {observation}\"\n",
    "        })\n",
    "    \n",
    "    return \"Error: Maximum iterations reached without answer\"\n",
    "\n",
    "print(\"âœ… Agent loop ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Test the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Simple Weather Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_agent(\"What's the weather like in Tokyo?\")\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Math Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_agent(\"If I have 15 apples and buy 7 more, then give away 9, how many do I have?\")\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Multi-Tool Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_agent(\n",
    "    \"What's the temperature in London and New York? What's the average?\"\n",
    ")\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Complex Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_agent(\n",
    "    \"I'm in Paris and want to visit a city that's 5 degrees warmer. Which city should I go to?\"\n",
    ")\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Challenge Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Add a New Tool\n",
    "\n",
    "Implement a `currency_converter(amount, from_currency, to_currency)` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_converter(args: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Convert between currencies.\n",
    "    Args format: \"100 USD to EUR\"\n",
    "    \n",
    "    TODO: Implement this function\n",
    "    Hints:\n",
    "    - Parse the args string to extract amount, from_currency, to_currency\n",
    "    - Use mock exchange rates\n",
    "    - Return result in same format as other tools\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Don't forget to:\n",
    "# 1. Add to TOOLS dictionary\n",
    "# 2. Update SYSTEM_PROMPT with tool description\n",
    "# 3. Test it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Improve Error Handling\n",
    "\n",
    "The agent should gracefully handle:\n",
    "- Invalid tool names\n",
    "- Malformed arguments\n",
    "- Tool execution failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify the agent loop to:\n",
    "# 1. Catch parsing errors and send them back as observations\n",
    "# 2. Let the LLM try again with corrected input\n",
    "# 3. Keep track of retry attempts\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Add Conversation History\n",
    "\n",
    "Make the agent remember previous questions in the same session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationalAgent:\n",
    "    \"\"\"\n",
    "    Agent that maintains conversation history.\n",
    "    \n",
    "    TODO: Implement this class\n",
    "    Methods:\n",
    "    - __init__: Initialize with system prompt\n",
    "    - ask(question): Process a question, return answer\n",
    "    - reset(): Clear conversation history\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Key Takeaways\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. **The ReAct Pattern**:\n",
    "   - Separates reasoning (THOUGHT) from action (ACTION)\n",
    "   - Grounds LLM outputs in real tool execution\n",
    "   - Provides feedback loop through OBSERVATION\n",
    "\n",
    "2. **Prompt Engineering is Critical**:\n",
    "   - Clear format instructions reduce parsing errors\n",
    "   - Examples in prompts improve consistency\n",
    "   - Temperature=0 for structured outputs\n",
    "\n",
    "3. **Agent Loop Architecture**:\n",
    "   ```python\n",
    "   while not done:\n",
    "       response = llm(messages)\n",
    "       action = parse(response)\n",
    "       if action is None: return answer\n",
    "       result = execute(action)\n",
    "       messages.append(observation)\n",
    "   ```\n",
    "\n",
    "4. **Tool Abstraction**:\n",
    "   - Tools are just Python functions\n",
    "   - Consistent interface (input/output format)\n",
    "   - Error handling is essential\n",
    "\n",
    "### Why Frameworks Exist:\n",
    "\n",
    "You just built what LangChain/LangGraph do under the hood! Frameworks add:\n",
    "- Pre-built tools\n",
    "- Better error handling\n",
    "- Streaming responses\n",
    "- Memory management\n",
    "- Monitoring/observability\n",
    "\n",
    "But now you understand **how they work**!\n",
    "\n",
    "### Production Considerations:\n",
    "\n",
    "- **Safety**: Validate tool inputs, sandbox execution\n",
    "- **Cost**: Each iteration = API call\n",
    "- **Latency**: Multiple round trips add up\n",
    "- **Reliability**: Need retry logic, timeouts\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "In Module 4, you'll add **memory** (RAG) so the agent can access knowledge bases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Additional Resources\n",
    "\n",
    "- [ReAct: Synergizing Reasoning and Acting (Paper)](https://arxiv.org/abs/2210.03629)\n",
    "- [MRKL Systems (Paper)](https://arxiv.org/abs/2205.00445)\n",
    "- [LangChain Agent Documentation](https://python.langchain.com/docs/modules/agents/)\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
